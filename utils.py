# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14akoKQSU1-NAOKba2HWhxEKWz0ePovzl
"""

import torch
import time
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

def measure_inference_time(model, input_size=(1, 3, 32, 32), device='cuda', num_runs=100):
    """Measure average inference time of a model"""
    model.eval()
    dummy_input = torch.randn(input_size).to(device)

    # Warmup
    for _ in range(10):
        with torch.no_grad():
            _ = model(dummy_input)

    # Measure time
    torch.cuda.synchronize() if device == 'cuda' else None
    start_time = time.time()

    for _ in range(num_runs):
        with torch.no_grad():
            _ = model(dummy_input)

    torch.cuda.synchronize() if device == 'cuda' else None
    end_time = time.time()

    avg_time = (end_time - start_time) / num_runs * 1000  # Convert to ms
    return avg_time

def plot_training_curves(teacher_acc, student_acc, teacher_loss=None, student_loss=None):
    """Plot training curves comparison"""
    fig, axes = plt.subplots(1, 2 if teacher_loss is None else 2, figsize=(15, 5))

    # Accuracy plot
    axes[0].plot(teacher_acc, label='Teacher', color='blue', linewidth=2)
    axes[0].plot(student_acc, label='Student', color='orange', linewidth=2)
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_title('Training Accuracy Comparison')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Loss plot (if available)
    if teacher_loss is not None and student_loss is not None:
        axes[1].plot(teacher_loss, label='Teacher', color='blue', linewidth=2)
        axes[1].plot(student_loss, label='Student', color='orange', linewidth=2)
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss')
        axes[1].set_title('Training Loss Comparison')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

def create_comparison_table(teacher_model, student_model, teacher_acc, student_acc, device='cuda'):
    """Create detailed comparison table"""

    # Count parameters
    teacher_params = sum(p.numel() for p in teacher_model.parameters())
    student_params = sum(p.numel() for p in student_model.parameters())

    # Measure inference time
    teacher_time = measure_inference_time(teacher_model, device=device)
    student_time = measure_inference_time(student_model, device=device)

    # Calculate model sizes (approximate)
    teacher_size = teacher_params * 4 / (1024**2)  # MB (assuming float32)
    student_size = student_params * 4 / (1024**2)  # MB

    # Create comparison data
    comparison_data = {
        'Metric': [
            'Parameters', 'Model Size (MB)', 'Accuracy (%)',
            'Inference Time (ms)', 'Speed Improvement', 'Parameter Reduction'
        ],
        'Teacher (ResNet-18)': [
            f'{teacher_params:,}', f'{teacher_size:.1f}', f'{teacher_acc*100:.1f}',
            f'{teacher_time:.2f}', '1.0x', '1.0x'
        ],
        'Student (Custom CNN)': [
            f'{student_params:,}', f'{student_size:.1f}', f'{student_acc*100:.1f}',
            f'{student_time:.2f}', f'{teacher_time/student_time:.1f}x',
            f'{teacher_params/student_params:.1f}x'
        ]
    }

    df = pd.DataFrame(comparison_data)
    return df

def visualize_model_comparison(comparison_df):
    """Create visualization of model comparison"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))

    # Extract numeric values for plotting
    teacher_params = float(comparison_df.iloc[0, 1].replace(',', ''))
    student_params = float(comparison_df.iloc[0, 2].replace(',', ''))

    teacher_size = float(comparison_df.iloc[1, 1])
    student_size = float(comparison_df.iloc[1, 2])

    teacher_acc = float(comparison_df.iloc[2, 1])
    student_acc = float(comparison_df.iloc[2, 2])

    teacher_time = float(comparison_df.iloc[3, 1])
    student_time = float(comparison_df.iloc[3, 2])

    # Parameters comparison
    axes[0, 0].bar(['Teacher', 'Student'], [teacher_params, student_params],
                   color=['#3B82F6', '#F59E0B'])
    axes[0, 0].set_ylabel('Parameters')
    axes[0, 0].set_title('Model Parameters')
    axes[0, 0].set_yscale('log')

    # Model size comparison
    axes[0, 1].bar(['Teacher', 'Student'], [teacher_size, student_size],
                   color=['#3B82F6', '#F59E0B'])
    axes[0, 1].set_ylabel('Size (MB)')
    axes[0, 1].set_title('Model Size')

    # Accuracy comparison
    axes[1, 0].bar(['Teacher', 'Student'], [teacher_acc, student_acc],
                   color=['#3B82F6', '#F59E0B'])
    axes[1, 0].set_ylabel('Accuracy (%)')
    axes[1, 0].set_title('Model Accuracy')
    axes[1, 0].set_ylim(80, 95)

    # Inference time comparison
    axes[1, 1].bar(['Teacher', 'Student'], [teacher_time, student_time],
                   color=['#3B82F6', '#F59E0B'])
    axes[1, 1].set_ylabel('Time (ms)')
    axes[1, 1].set_title('Inference Time')

    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
    plt.show()

def save_results(teacher_model, student_model, teacher_acc, student_acc,
                train_history, output_dir='results/'):
    """Save all results and models"""
    import os
    os.makedirs(output_dir, exist_ok=True)

    # Save models
    torch.save(teacher_model.state_dict(), f'{output_dir}/teacher_model.pth')
    torch.save(student_model.state_dict(), f'{output_dir}/student_model.pth')

    # Save training history
    np.save(f'{output_dir}/training_history.npy', train_history)

    # Create and save comparison table
    comparison_df = create_comparison_table(teacher_model, student_model,
                                          teacher_acc, student_acc)
    comparison_df.to_csv(f'{output_dir}/comparison_results.csv', index=False)

    print(f"Results saved to {output_dir}")
    return comparison_df